{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-07-18T16:12:15.568262Z",
     "start_time": "2023-07-18T16:12:15.556859200Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "import re\n",
    "import emoji\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from textblob import TextBlob\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Define the start and end dates for the data.\n",
    "start_date = '2017-02-01'\n",
    "end_date = '2020-12-31'\n",
    "\n",
    "# Download the historical data for the S&P 500 index using the ^GSPC ticker symbol.\n",
    "sp500 = yf.download('^GSPC', start=start_date, end=end_date)\n",
    "\n",
    "# The variable `sp500` now contains a DataFrame with the historical data for the S&P 500 index."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# Drop the columns from the DataFrame\n",
    "sp500 = sp500.drop(columns=['Volume', 'Adj Close'])\n",
    "sp500_tb = sp500.copy()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-18T16:12:17.908524400Z",
     "start_time": "2023-07-18T16:12:17.902973400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "target_directory = '.\\stocks'\n",
    "if not os.path.exists(target_directory):\n",
    "    os.makedirs(target_directory)\n",
    "\n",
    "csv_filename = 'sp500.csv'\n",
    "sp500.to_csv(os.path.join(target_directory, csv_filename), index=True, encoding='utf-8')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-18T16:13:20.019949300Z",
     "start_time": "2023-07-18T16:13:20.007474400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "# Define the URLs for the CSV files.\n",
    "url_musk = 'https://raw.githubusercontent.com/maorisraelii/twitter-sentiment-analysis/main/Musk(2014-2019).csv'\n",
    "url_biden = 'https://raw.githubusercontent.com/maorisraelii/twitter-sentiment-analysis/main/Biden(2007-2020).csv'\n",
    "url_trump = 'https://raw.githubusercontent.com/maorisraelii/twitter-sentiment-analysis/main/Trump(2017-2021).csv'\n",
    "url_bill = 'https://raw.githubusercontent.com/maorisraelii/twitter-sentiment-analysis/main/Bill_Gates.csv'\n",
    "url_jeff = 'https://raw.githubusercontent.com/maorisraelii/twitter-sentiment-analysis/main/Jeff_Bezos.csv'\n",
    "url_tim = 'https://raw.githubusercontent.com/maorisraelii/twitter-sentiment-analysis/main/Tim_Cook.csv'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-18T16:15:48.968594100Z",
     "start_time": "2023-07-18T16:15:48.924079200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "# Read the CSV files into DataFrames.\n",
    "musk = pd.read_csv(url_musk, encoding= 'unicode_escape')\n",
    "biden = pd.read_csv(url_biden, encoding= 'unicode_escape')\n",
    "trump = pd.read_csv(url_trump, encoding= 'unicode_escape',on_bad_lines= 'skip')\n",
    "bill = pd.read_csv(url_bill, encoding= 'unicode_escape')\n",
    "jeff = pd.read_csv(url_jeff, encoding= 'unicode_escape')\n",
    "tim = pd.read_csv(url_tim, encoding= 'unicode_escape')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-18T16:15:55.841963800Z",
     "start_time": "2023-07-18T16:15:49.678566500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "# Convert 'time' column in the dataset to datetime format\n",
    "trump['time'] = pd.to_datetime(trump['time'])\n",
    "biden['time'] = pd.to_datetime(biden['time'], dayfirst=True)\n",
    "musk['time'] = pd.to_datetime(musk['date'])\n",
    "bill['time'] = pd.to_datetime(bill['time_stamp_UTC'])\n",
    "jeff['time'] = pd.to_datetime(jeff['created_at'])\n",
    "tim['time'] = pd.to_datetime(tim['created_at'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-18T16:15:55.962623Z",
     "start_time": "2023-07-18T16:15:55.843965400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "# Convert 'tweet' column in the dataset\n",
    "trump.rename(columns={'tweet': 'tweet'}, inplace=True)\n",
    "biden.rename(columns={'tweet': 'tweet'}, inplace=True)\n",
    "musk.rename(columns={'tweet': 'tweet'}, inplace=True)\n",
    "bill.rename(columns={'tweet_text': 'tweet'}, inplace=True)\n",
    "jeff.rename(columns={'text': 'tweet'}, inplace=True)\n",
    "tim.rename(columns={'text': 'tweet'}, inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-18T16:15:55.985875900Z",
     "start_time": "2023-07-18T16:15:55.964621900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "# Define a function to replace emojis with words\n",
    "def replace_emojis_with_words(text):\n",
    "    # Replace each emoji with its corresponding description\n",
    "    text_with_words = emoji.demojize(text)\n",
    "    return text_with_words"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-18T16:15:56.054873300Z",
     "start_time": "2023-07-18T16:15:55.985875900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "# Define regular expressions to match links and emojis\n",
    "link_pattern = r'https?://\\S+'\n",
    "emoji_pattern = re.compile(\"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "        \"]+\", flags=re.UNICODE)\n",
    "\n",
    "def clean_dataset(dataset, tweet_column = 'tweet', date_column = 'time'):\n",
    "    dataset[tweet_column] = dataset[tweet_column].fillna('')  # Replace NaN values with an empty string\n",
    "    dataset = dataset[~dataset[tweet_column].str.match(link_pattern)]  # Remove rows with tweets that contain only links\n",
    "    dataset = dataset[~dataset[tweet_column].str.contains(emoji_pattern)]  # Remove rows with tweets that contain emojis\n",
    "    dataset[tweet_column] = dataset[tweet_column].apply(replace_emojis_with_words)\n",
    "    dataset = dataset.dropna(axis=0, how='all')  # Drop rows with all NaN values\n",
    "    dataset = dataset.dropna(axis=1, how='all')  # Drop columns with all NaN values\n",
    "    dataset = dataset.reset_index(drop=True)  # Reset the index of the dataset\n",
    "    dataset.dropna(subset=[date_column], inplace=True)  # Drop rows with NaN values in the date column\n",
    "    return dataset"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-18T16:15:56.054873300Z",
     "start_time": "2023-07-18T16:15:55.985875900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "# Clean datasets\n",
    "musk = clean_dataset(musk)\n",
    "biden = clean_dataset(biden)\n",
    "trump = clean_dataset(trump)\n",
    "bill = clean_dataset(bill)\n",
    "jeff = clean_dataset(jeff)\n",
    "tim = clean_dataset(tim)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-18T16:16:02.554405700Z",
     "start_time": "2023-07-18T16:15:55.985875900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "# Filter the dataset for the specified time range\n",
    "trump = trump[(trump['time'] >= start_date) & (trump['time'] <= end_date)]\n",
    "biden = biden[(biden['time'] >= start_date) & (biden['time'] <= end_date)]\n",
    "musk = musk[(musk['time'] >= start_date) & (musk['time'] <= end_date)]\n",
    "bill = bill[(bill['time'] >= start_date) & (bill['time'] <= end_date)]\n",
    "jeff = jeff[(jeff['time'] >= start_date) & (jeff['time'] <= end_date)]\n",
    "tim = tim[(tim['time'] >= start_date) & (tim['time'] <= end_date)]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-18T16:16:02.563648100Z",
     "start_time": "2023-07-18T16:16:02.537407200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "target_directory = './tweets'\n",
    "if not os.path.exists(target_directory):\n",
    "    os.makedirs(target_directory)\n",
    "\n",
    "trump.to_csv(os.path.join(target_directory,'trump.csv'), index=False, encoding='utf-8')\n",
    "biden.to_csv(os.path.join(target_directory,'biden.csv'), index=False, encoding='utf-8')\n",
    "musk.to_csv(os.path.join(target_directory,'musk.csv'), index=False, encoding='utf-8')\n",
    "bill.to_csv(os.path.join(target_directory,'bill.csv'), index=False, encoding='utf-8')\n",
    "jeff.to_csv(os.path.join(target_directory,'jeff.csv'), index=False, encoding='utf-8')\n",
    "tim.to_csv(os.path.join(target_directory,'tim.csv'), index=False, encoding='utf-8')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-18T16:16:03.041460900Z",
     "start_time": "2023-07-18T16:16:02.560647200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "# Function to perform sentiment analysis using Vader\n",
    "def perform_sentiment_analysis_v(df):\n",
    "    analyzed_df = df.copy()\n",
    "    analyzed_df['sentiment'] = ''\n",
    "    analyzed_df['polarity'] = ''\n",
    "\n",
    "    # Create an instance of the Vader sentiment analyzer\n",
    "    analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "    for index, row in analyzed_df.iterrows():\n",
    "        tweet = row['tweet']\n",
    "        sentiment, compound_score = get_sentiment_label_v(analyzer.polarity_scores(tweet))\n",
    "        analyzed_df.at[index, 'sentiment'] = sentiment\n",
    "        analyzed_df.at[index, 'polarity'] = compound_score\n",
    "\n",
    "    return analyzed_df\n",
    "\n",
    "# Function to get sentiment label and compound score based on Vader sentiment scores\n",
    "def get_sentiment_label_v(sentiment_scores):\n",
    "    compound_score = sentiment_scores['compound']\n",
    "\n",
    "    if compound_score >= 0.05:\n",
    "        sentiment_label = 'positive'\n",
    "    elif compound_score <= -0.05:\n",
    "        sentiment_label = 'negative'\n",
    "    else:\n",
    "        sentiment_label = 'neutral'\n",
    "\n",
    "    return sentiment_label, compound_score"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-18T16:16:04.396728300Z",
     "start_time": "2023-07-18T16:16:04.353899600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "# Perform sentiment analysis using Vader\n",
    "analyzed_musk_vader = perform_sentiment_analysis_v(musk)\n",
    "analyzed_biden_vader = perform_sentiment_analysis_v(biden)\n",
    "analyzed_trump_vader = perform_sentiment_analysis_v(trump)\n",
    "analyzed_jeff_vader = perform_sentiment_analysis_v(jeff)\n",
    "analyzed_tim_vader = perform_sentiment_analysis_v(tim)\n",
    "analyzed_bill_vader = perform_sentiment_analysis_v(bill)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-18T16:16:14.242918100Z",
     "start_time": "2023-07-18T16:16:05.815341Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "# Group by the date and calculate the average sentiment for each day\n",
    "day_grouped_musk_vader = analyzed_musk_vader.groupby(analyzed_musk_vader['time'].dt.date)['polarity'].mean()\n",
    "day_grouped_trump_vader= analyzed_trump_vader.groupby(analyzed_trump_vader['time'].dt.date)['polarity'].mean()\n",
    "day_grouped_biden_vader = analyzed_biden_vader.groupby(analyzed_biden_vader['time'].dt.date)['polarity'].mean()\n",
    "day_grouped_jeff_vader = analyzed_jeff_vader.groupby(analyzed_jeff_vader['time'].dt.date)['polarity'].mean()\n",
    "day_grouped_tim_vader = analyzed_tim_vader.groupby(analyzed_tim_vader['time'].dt.date)['polarity'].mean()\n",
    "day_grouped_bill_vader = analyzed_bill_vader.groupby(analyzed_bill_vader['time'].dt.date)['polarity'].mean()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-18T16:16:14.881221900Z",
     "start_time": "2023-07-18T16:16:14.245917600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "sp500['biden'] = day_grouped_biden_vader\n",
    "sp500['musk'] = day_grouped_musk_vader\n",
    "sp500['trump'] = day_grouped_trump_vader\n",
    "sp500['tim'] = day_grouped_tim_vader\n",
    "sp500['bill'] = day_grouped_bill_vader\n",
    "sp500['jeff'] = day_grouped_jeff_vader"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-18T16:16:14.881221900Z",
     "start_time": "2023-07-18T16:16:14.846571600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "sp500.interpolate(method='linear', inplace=True)\n",
    "sp500.fillna(method='bfill', inplace=True)\n",
    "sp500.fillna(method='ffill', inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-18T16:16:14.881221900Z",
     "start_time": "2023-07-18T16:16:14.867410700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "target_directory = './sentiment'\n",
    "if not os.path.exists(target_directory):\n",
    "    os.makedirs(target_directory)\n",
    "\n",
    "sp500.to_csv(os.path.join(target_directory,'data_vader.csv'), index=True, encoding='utf-8')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-18T16:17:06.846248800Z",
     "start_time": "2023-07-18T16:17:06.783569400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "# Function to perform sentiment analysis using TextBlob\n",
    "def perform_sentiment_analysis_tb(df):\n",
    "    analyzed_df = df.copy()\n",
    "    analyzed_df['sentiment'] = ''\n",
    "    analyzed_df['polarity'] = ''\n",
    "\n",
    "    for index, row in analyzed_df.iterrows():\n",
    "        tweet = row['tweet']\n",
    "        sentiment, polarity = get_sentiment_label_tb(TextBlob(tweet).sentiment)\n",
    "        analyzed_df.at[index, 'sentiment'] = sentiment\n",
    "        analyzed_df.at[index, 'polarity'] = polarity\n",
    "\n",
    "    return analyzed_df\n",
    "\n",
    "# Function to get sentiment label, subjectivity, and polarity based on sentiment score\n",
    "def get_sentiment_label_tb(sentiment):\n",
    "    polarity = sentiment.polarity\n",
    "    subjectivity = sentiment.subjectivity\n",
    "\n",
    "    if polarity > 0:\n",
    "        sentiment_label = 'positive'\n",
    "    elif polarity < 0:\n",
    "        sentiment_label = 'negative'\n",
    "    else:\n",
    "        sentiment_label = 'neutral'\n",
    "\n",
    "    return sentiment_label, polarity"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-18T16:17:17.514888200Z",
     "start_time": "2023-07-18T16:17:17.504822200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "# Perform sentiment analysis using TextBlob\n",
    "analyzed_musk_textblob = perform_sentiment_analysis_tb(musk)\n",
    "analyzed_biden_textblob = perform_sentiment_analysis_tb(biden)\n",
    "analyzed_trump_textblob = perform_sentiment_analysis_tb(trump)\n",
    "analyzed_jeff_textblob = perform_sentiment_analysis_tb(jeff)\n",
    "analyzed_tim_textblob = perform_sentiment_analysis_tb(tim)\n",
    "analyzed_bill_textblob = perform_sentiment_analysis_tb(bill)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-18T16:17:33.126066500Z",
     "start_time": "2023-07-18T16:17:18.392230200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "# Group by the date and calculate the average sentiment for each day\n",
    "day_grouped_musk_textblob = analyzed_musk_textblob.groupby(analyzed_musk_textblob['time'].dt.date)['polarity'].mean()\n",
    "day_grouped_trump_textblob = analyzed_trump_textblob.groupby(analyzed_trump_textblob['time'].dt.date)['polarity'].mean()\n",
    "day_grouped_biden_textblob = analyzed_biden_textblob.groupby(analyzed_biden_textblob['time'].dt.date)['polarity'].mean()\n",
    "day_grouped_jeff_textblob = analyzed_jeff_textblob.groupby(analyzed_jeff_textblob['time'].dt.date)['polarity'].mean()\n",
    "day_grouped_tim_textblob = analyzed_tim_textblob.groupby(analyzed_tim_textblob['time'].dt.date)['polarity'].mean()\n",
    "day_grouped_bill_textblob = analyzed_bill_textblob.groupby(analyzed_bill_textblob['time'].dt.date)['polarity'].mean()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-18T16:17:33.702482Z",
     "start_time": "2023-07-18T16:17:33.130065900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "sp500_tb['biden'] = day_grouped_biden_textblob\n",
    "sp500_tb['musk'] = day_grouped_musk_textblob\n",
    "sp500_tb['trump'] = day_grouped_trump_textblob\n",
    "sp500_tb['tim'] = day_grouped_tim_textblob\n",
    "sp500_tb['bill'] = day_grouped_bill_textblob\n",
    "sp500_tb['jeff'] = day_grouped_jeff_textblob"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-18T16:17:33.726044800Z",
     "start_time": "2023-07-18T16:17:33.701482700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "sp500_tb.interpolate(method='linear', inplace=True)\n",
    "sp500_tb.fillna(method='bfill', inplace=True)\n",
    "sp500_tb.fillna(method='ffill', inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-18T16:17:33.731045100Z",
     "start_time": "2023-07-18T16:17:33.710512500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "target_directory = './sentiment'\n",
    "if not os.path.exists(target_directory):\n",
    "    os.makedirs(target_directory)\n",
    "\n",
    "sp500_tb.to_csv(os.path.join(target_directory,'data_textblob.csv'), index=True, encoding='utf-8')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-18T16:17:42.487774700Z",
     "start_time": "2023-07-18T16:17:42.431775Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
